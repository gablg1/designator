\documentclass{beamer}
\usepackage[orientation=landscape, size=a0, scale=1.4]{beamerposter}
\usepackage[absolute,overlay]{textpos}
\usepackage{multicol}
\usepackage{graphics}
\usepackage{url, enumitem}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{tikz}
\usetikzlibrary{fit,positioning}
  \usetheme{CambridgeUS}
    \title[Designator]{Designator}
    \addtobeamertemplate{frametitle}{\vskip0.6ex}{}
\newcommand{\N}{\mathcal{N}}	
\usepackage{scrextend}
\changefontsizes{29pt}
\begin{document}

%\begin{block}{\centering \Huge {Title Goes Here}}
%\end{block}
\begin{frame}{\centerline{\Huge Gabriel Doesn't Know How to Refactor Code}}
\begin{textblock}{5}(.15,.85)
\begin{block}{Introduction}
Over the past decade, aesthetics have gained a lot of importance in the decisions companies
make in how they design websites, and user experience is at the core of this trend.  In this paper, we develop a way to automate this process by generating color suggestions based on what we call the "Ugly Duckling" problem: essentially recommending what popular similar websites contain that the input website does not yet have. Using Ugly Duckling, we got results that are consistently better than color recommenders based on more classical techniques such as Naive Bayes, SVM, and Random Forest classification. It is not immediately clear, however, how to find "similar websites." Especially when the website dabatase is large, diffing a screenshot or even the color histogram of a given input website against thousands or millions of other websites can prove to be a daunting task. This paper applies different sorts of unsupervised clustering including KMeans and Affinity Propagation to solve this problem. Once the websites are clustered, the system can place
an input website into a cluster. Diffing the input against all websites in a cluster can be
done much faster than within the whole database,anybody faanybody fa and the system will only have to consider
recommendations that are relevant to that specific cluster. 
\end{block}

\begin{block}{Data}
Our data consists of the 5000 most popular websites on the web drawn from the Alexa database, whose screenshots we got using PhantomJS. To keep the data clean, we purged all uninteresting websites that have only 2 or less colors. For feature vectors, we used both ~7000 dimensional RGB arrays and $D=$~17000 dimensional binned histograms. The binned histograms are color histograms where we place color values into bins of size 10, so that we consider the existence of exactly $D$ colors as opposed to the usual 255 * 255 * 255 which is too large.
\end{block}

\begin{block}{Problem and Error Measuring}
Website data is completely unlabeled and it is not immediately clear what a "good" color recommendation would be. To address this issue, we remove a color $c$ from each website in the test set and ask our system to try to recommend it back. In this framework, recommendation becomes a classification problem that tries to infer $c$ out of ~17000 different possible colors, so throughout the paper we consider both the classification accuracy $\tau$ as a percentage (greater is better, doesn't take into account how distant the colors are) and the mean color recommendation error $\delta$ (lower is better, takes into account how distant the colors are).
$$\tau_Y = \frac{\text{Correct}}{\text{Total}} = \frac{\sum_n I[r_n = c_n]}{n}$$
$$\delta_Y = \sum_n |r_n - c_n|$$
\end{block}

\begin{block}{Model of the Problem}
Consider our problem represented by the following graphical model
\begin{figure}
\centering
\begin{tikzpicture}
\tikzstyle{main}=[circle, minimum size = 10mm, thick, draw =black!80, node distance = 16mm]
\tikzstyle{connect}=[-latex, thick]
\tikzstyle{box}=[rectangle, draw=black!100]
\node[main, fill = white!100] (Color) [above=of Normal] {$C$ };
\node[main] (Web) [right=of Color] {$W$};
\node[main,fill={rgb:red,243;green,243;blue,243}] (WebLessColor) [above=of Web, yshift=15mm, xshift=-10mm] {$W_{c}$};
  \path (Normal) edge [connect] (Color)
  	(Web) edge [connect] (Color)
  	(Color) edge [connect] (WebLessColor)
  	(Web) edge [connect] (WebLessColor);
\end{tikzpicture}
\end{figure}
Where $W$ is the initial (unobserved) website, $C$ is the removed color that we wish to predict, and $W_c$ is the website
that we observe, after having $C$ removed. In our case, $C$ is chosen uniformly from $W$ (except we never let $C$ be a
background color, i.e. a color that takes up more than 40\% of the page, because those colors are uninteresting as
recommendations).
\end{block}


\begin{block}{Approach - The Ugly Duckling Algorithm}
Given the model above, it makes sense to try to predict the color $C$ by looking at websites similar to $W_c$, hoping
that they might contain $C$ is as well. From this intuition we developed theUgly Duckling recommendation algorithm: given some input website $x$, we take a list of similar websites $Y$ and find the color not present in $x$ that appears most consistently in $Y$.
$$r = \on{argmax}_{d} \on{mean}(Y_d) $$
where $Y_d$ is the $d$-th color of a website in $Y$. We also explored with similar formulas that also take variance into account such as
$$r = \on{argmax}_{d} \frac{E\left[Y_d\right]}{\on{var}(Y_d)} $$
but found the first one to be the most reliable.

Now we are left with the problem of finding websites that are "similar" to our input. Our first idea was to use
clustering algorithms such as KMeans and Affinity Propagation. We used the sk-learn version of KMeans and implemented
Affinity Propagation ourselves in Python. The results of these algorithms on our data set can be seen in the following
section.
\end{block}


\end{textblock}

\begin{textblock}{5}(5.5, .85)

\begin{block}{K-Means using Images}
\includegraphics[scale=.5]{imgkmeans.png}
\end{block}
\begin{block}{ K-Means using Binned Histograms}
\includegraphics[scale=.5]{binKmeans.jpg}
\end{block}
\begin{block}{Affinity Propogation using Image}
\includegraphics[scale=.5]{affPropImg.jpg}
\end{block}
\begin{block}{Affinity Propogation using Binned Histograms}
\includegraphics[scale=.5]{binAffProp.jpg}
\end{block}
\end{textblock}

\begin{textblock}{5}(10.75, .85)
\begin{block}{Intermediate Solutions - The Life of a Duck}
We initially started with a naive recommendation scheme that considers only the image in the data set that is closest to our input (by diffing
histograms). From there, we recommend adding the color that would bring the two images the
closest.

Then we moved on to the Ugly Duckling algorithm using clusters. Given an input website, we'd first place it into a
cluster and consider that cluster the set of similar websites where we'd try to find the color $C$. Initially we used K-means and
Affinity Propagation for clustering, which already improved our classification rate by over 50 times.
\end{block}

\begin{block}{Final solution - Going Full Duckling}
The Ugly Duckling idea is based on the assumption that similar websites have a higher chance of having the color that
was removed from website $x$. Because of this, we decided to dump the classical clustering algorithms mentioned above in favor of
generating clusters on the fly, based on which websites have the most colors similar to our input. To do this, we
calculate similarities between two websites via the following ratio known as the Jaccard index:
$$\frac{|A \cap B|}{|A \cup B|}$$

Where $A$ is the set of colors in website $a$ and $B$ is the set of colors in website $b$. The higher the ratio, the
more similar two sites are. In this case, we chose the $n$ websites that had the highest ratios, called that a cluster,
and then ran our Duckling recommender on the generated set.

Using this new approach we get a mean cluster Jaccard index of approximately 0.15 as opposed to 0.8 with the
Kmeans/Affinity Propagation clusters. The increased Jaccard index also reflected on an increased classification accuracy
(and a lower mean color error) as depicted in the Results section below.

\end{block}
\begin{block}{Mean Color Recommendation}
\includegraphics[scale=.9]{colorError.png}
\end{block}
\begin{block}{Designator Classifier Results}
\includegraphics[scale=.9]{newplot.png}
\end{block}
\end{textblock}
\end{frame}
\end{document}
